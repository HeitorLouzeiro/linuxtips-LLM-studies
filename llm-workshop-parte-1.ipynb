{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "85488dad-010f-4700-ab38-b1ec404c0beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2cf39ce-0968-41d2-b7d6-b1748559dea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gcp-starter'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv('./.env')\n",
    "os.environ.get('PINECONE_ENV')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dbc64a",
   "metadata": {},
   "source": [
    "* Instantiating the API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f74ceeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv('OPENAI_SECREY_KEY')\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "PINECONE_ENV = os.getenv('PINECONE_ENV')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ace51d",
   "metadata": {},
   "source": [
    "## LangChain getting started\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f9b1dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOpenAI\u001b[0m\n",
      "Params: {'model_name': 'text-davinci-003', 'temperature': 0.7, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'logit_bias': {}, 'max_tokens': 512}\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model_name='text-davinci-003', temperature=0.7, max_tokens=512, openai_api_key=OPENAI_API_KEY)\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe1804b",
   "metadata": {},
   "source": [
    "* Asking AI a question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26c0f72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = llm('explique como funções python funcionam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ea6abe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Funções Python são blocos de código que executam uma tarefa específica quando são chamados. Elas são definidas usando a palavra-chave def. Uma função recebe argumentos e, opcionalmente, retorna um valor. Funções Python são usadas para modularizar a lógica do programa, tornando mais fácil de ler e debugar o código. Uma função também pode ser chamada repetidamente para executar a mesma tarefa várias vezes, tornando o código mais eficiente.\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb03ac7",
   "metadata": {},
   "source": [
    "* Count Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bddcf343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "print(llm.get_num_tokens('explique como funções python funcionam'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3d0917",
   "metadata": {},
   "source": [
    "* list of questions and answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e0d9d3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = llm.generate(['... é a capital da França',\n",
    "                       'qual é a formula da área de um círculo?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5af7795d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Generation(text='?\\n\\nParis.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nA área de um círculo é dada por A = π.r², onde r é o raio do círculo.', generation_info={'finish_reason': 'stop', 'logprobs': None})]]\n"
     ]
    }
   ],
   "source": [
    "print(output.generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "04f3e77e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?\\n\\nParis.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.generations[0][0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a8c0f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = llm.generate(['escreva um slogan original para um restaurante de sushi'] * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b1f62778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Sushi com sabor de autenticidade: Venha sentir o verdadeiro sabor do Oriente!\"\n",
      "\n",
      "\"A frescura do sabor japonês, no coração da cidade!\"\n",
      "\n",
      "\"Sushi com sabores que vão te surpreender!\""
     ]
    }
   ],
   "source": [
    "for o in output.generations:\n",
    "    print(o[0].text, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138919ac",
   "metadata": {},
   "source": [
    "## ChatModels: GPT-3.5-Turbo e GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "170974db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import(\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca0770d",
   "metadata": {},
   "source": [
    "- AIMESSAGE - Helps define the assistant's behavior.\n",
    "- HUMANMESSAGE - What do we ask the assistant\n",
    "- SYSTEMMESSAGE - Helps store previous responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "780f2d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.5, max_tokens=1024)\n",
    "messages = [\n",
    "    SystemMessage(content='Você é um especialista em machine learning que responde tudo em português.'),\n",
    "    HumanMessage(content='explique em um parágrafo o que é machine learning.')\n",
    "]\n",
    "output = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "784c864d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning, ou aprendizado de máquina, é um campo da inteligência artificial que se baseia na capacidade dos computadores de aprender e melhorar a partir de dados, sem serem explicitamente programados. Por meio de algoritmos e modelos estatísticos, o machine learning permite que as máquinas analisem grandes quantidades de dados e identifiquem padrões, tomando decisões e realizando tarefas de forma autônoma. Essa abordagem é amplamente utilizada em diversas áreas, como reconhecimento de padrões, previsão de resultados, classificação de dados e recomendação de produtos, entre outros.\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84156a26",
   "metadata": {},
   "source": [
    "## Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c429cfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ed9ba1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['idioma', 'virus'] template='Você é um virologista experiente.\\nEscreva algumas frases sobre o sequinte {virus} em {idioma}.'\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"Você é um virologista experiente.\n",
    "Escreva algumas frases sobre o sequinte {virus} em {idioma}.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['virus', 'idioma'],\n",
    "    template=template\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5dc2a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. HIV is a virus that can cause serious health complications if left untreated.\n",
      "2. Early detection and treatment of HIV can help reduce the risk of further health complications.\n",
      "3. Understanding how HIV is transmitted is important for preventing the spread of infection.\n",
      "4. HIV is a manageable condition with the right combination of medications.\n",
      "5. Effective HIV prevention strategies such as using condoms and practicing safe sex are essential for reducing the risk of transmission.\n",
      "6. Educating yourself and your community about HIV can help reduce stigma and create an environment of acceptance.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model_name='text-davinci-003', temperature=0.7)\n",
    "output = llm(prompt.format(virus='HIV', idioma='Inglês'))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab6dca9",
   "metadata": {},
   "source": [
    "## Simple Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbfc5213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.5)\n",
    "\n",
    "template = \"\"\"Você é um virologista experiente.\n",
    "Escreva um resumo sobre o sequinte {virus} em {idioma}.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['virus', 'idioma'],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "output = chain.run({'virus': 'HIV', 'idioma': 'english'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09ed058c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HIV, or Human Immunodeficiency Virus, is a viral infection that attacks the immune system, specifically the CD4 cells (T cells), which play a crucial role in fighting off infections. If left untreated, HIV can lead to the development of acquired immunodeficiency syndrome (AIDS).\\n\\nHIV is primarily transmitted through unprotected sexual intercourse, sharing contaminated needles, or from an infected mother to her child during childbirth or breastfeeding. It can also be transmitted through blood transfusions, though this is now rare due to improved screening techniques.\\n\\nUpon infection, individuals may experience flu-like symptoms, such as fever, fatigue, and swollen lymph nodes. However, these symptoms can be mild and easily overlooked. As the virus progresses, it weakens the immune system, making the individual more susceptible to various infections and diseases.\\n\\nThere is currently no cure for HIV, but it can be managed through antiretroviral therapy (ART). ART involves a combination of medications that suppress the replication of the virus, allowing the immune system to recover and function effectively. With proper treatment, people living with HIV can lead long and healthy lives.\\n\\nPrevention is crucial in controlling the spread of HIV. This includes practicing safe sex by using condoms, avoiding sharing needles, and getting tested regularly, especially if engaging in high-risk behaviors. Additionally, HIV can be prevented through pre-exposure prophylaxis (PrEP), a medication taken by individuals at high risk of contracting the virus.\\n\\nIn conclusion, HIV is a chronic viral infection that affects the immune system and can lead to AIDS if left untreated. While there is currently no cure, effective treatment options exist that can allow individuals to live fulfilling lives. Prevention measures, such as safe sex practices and regular testing, are essential in reducing the transmission of HIV.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04c9392",
   "metadata": {},
   "source": [
    "## Sequential Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c738d6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\n",
      "\n",
      "def softmax(x): \n",
      "    # x is a vector/list of inputs \n",
      "    # compute the exponential of each element \n",
      "    exps = [np.exp(i) for i in x] \n",
      "    # compute the sum of all exponentials \n",
      "    sum_of_exps = np.sum(exps) \n",
      "    # compute the softmax \n",
      "    softmax = [j/sum_of_exps for j in exps] \n",
      "    # return the softmax \n",
      "    return softmax\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mA função softmax é uma função de ativação que é comumente usada na camada de saída de uma rede neural quando se trata de classificação multiclasse.\n",
      "A função recebe um vetor ou lista de valores de entrada e realiza as seguintes etapas para calcular a saída softmax:\n",
      "\n",
      "1. Para cada elemento de entrada x, a função calcula a exponencial de x usando a função np.exp(i), onde np é uma biblioteca de NumPy.\n",
      "2. Esses valores exponenciais são armazenados em uma lista chamada \"exps\".\n",
      "3. Em seguida, a função calcula a soma de todos os elementos da lista \"exps\" usando a função np.sum(exps) e armazena o resultado na variável \"sum_of_exps\".\n",
      "4. Agora, para calcular a saída softmax para cada elemento, a função divide cada exponencial pela soma dos exponenciais. Isso é feito para normalizar os valores e garantir que a soma das saídas seja 1.\n",
      "5. Esses valores normalizados são então armazenados em uma nova lista chamada \"softmax\".\n",
      "6. Por fim, a função retorna a lista \"softmax\", que contém as saídas softmax para cada elemento de entrada.\n",
      "\n",
      "Em resumo, a função softmax converte um vetor de valores em uma distribution de probabilidade usando a função exponencial softmax.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "llm1 = OpenAI(model_name='text-davinci-003', temperature=0.7, max_tokens=1024)\n",
    "prompt1 = PromptTemplate(\n",
    "    input_variables=['conceito'],\n",
    "    template=\"\"\"Você é um cientista experiente e programador Python.\n",
    "    Escreva uma função que implementa o conceito de {conceito}.\"\"\"\n",
    ")\n",
    "\n",
    "chain1 = LLMChain(llm=llm1, prompt=prompt1)\n",
    "\n",
    "#--- segunda chain ----\n",
    "\n",
    "llm2 = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=1.2)\n",
    "prompt2 = PromptTemplate(\n",
    "    input_variables=['function'],\n",
    "    template=\"\"\"Dada a função {function} Python, descreva como funciona da forma mais detalhada possível.\"\"\"\n",
    ")\n",
    "\n",
    "chain2 = LLMChain(llm=llm2, prompt=prompt2)\n",
    "\n",
    "overall_chain = SimpleSequentialChain(chains=[chain1, chain2], verbose=True)\n",
    "output = overall_chain.run(\"softmax\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe2d269",
   "metadata": {},
   "source": [
    "## LangChain Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2e820a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146306.05007233328"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exemplo exponenciação\n",
    "\n",
    "5.1 ** 7.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb16758",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.agents.agent_toolkits import create_python_agent\n",
    "from langchain_experimental.tools.python.tool import PythonAstREPLTool\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a2e7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "agent_executor = create_python_agent(\n",
    "    llm=llm,\n",
    "    tool=PythonAstREPLTool(),\n",
    "    verbose=True\n",
    ")\n",
    "agent_executor.run('qual a resposta para 5.1 elevado à potência de 7.3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
